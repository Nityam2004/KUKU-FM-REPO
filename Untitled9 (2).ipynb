{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivclZH8CS4OJ",
        "outputId": "7fdb7bb6-d88a-44ad-ee16-b931e97ca4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.11/dist-packages (2.25.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (5.29.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-texttospeech pydub numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi2ccuu_THL2",
        "outputId": "c801710b-cb7c-413f-cdd5-d8112cec217f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.11/dist-packages (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-texttospeech) (5.29.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.69.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-texttospeech) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (4.9)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-texttospeech) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers pydub google-cloud-texttospeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6R5TO6CTRi3",
        "outputId": "bce32315-3ffa-4f71-c996-36c0bf096008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "# prompt: no module named fitz\n",
        "\n",
        "!pip install pymupdf openai moviepy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ORxvS3SKwx",
        "outputId": "a6525ddd-2c4a-4f59-e60c-37a0157fc731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai moviepy\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4S75S-TgTHPN"
      },
      "outputs": [],
      "source": [
        "import fitz  # PDF handling\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "from pydub import AudioSegment\n",
        "from google.cloud import texttospeech\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "import moviepy.editor as mpy\n",
        "import requests  # For downloading images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J7NoNFIrTlUj"
      },
      "outputs": [],
      "source": [
        "def read_text_file(file_path):\n",
        "    \"\"\"Reads a text file and returns its content.\"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return file.read()\n",
        "\n",
        "def read_pdf_file(file_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    doc = fitz.open(file_path)\n",
        "    text = \"\\n\".join([page.get_text() for page in doc])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bc7dlLscTlX9"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Cleans text and splits it into sentences.\"\"\"\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    return sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HAWAvUmTla2",
        "outputId": "8754c1ff-3f1f-4880-9c04-910a9b57f47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvC28lXoTld2",
        "outputId": "4d744acd-029b-4fd6-bb2f-da438c76df04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a pre-trained BERT-based emotion classifier\n",
        "emotion_classifier = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\", top_k=1)\n",
        "\n",
        "def detect_emotion(text):\n",
        "    \"\"\"Detects emotion from text using a better transformer model.\"\"\"\n",
        "    result = emotion_classifier(text[:512])  # Process first 512 tokens\n",
        "    emotion = result[0][0]['label']  # Get top emotion\n",
        "    return emotion.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "79cibZFpUu1M"
      },
      "outputs": [],
      "source": [
        "from google.cloud import texttospeech\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/kukufm-f6e59d5c8710.json\"  # Google Cloud Key\n",
        "credentials = service_account.Credentials.from_service_account_file(\"/content/kukufm-f6e59d5c8710.json\")\n",
        "client = texttospeech.TextToSpeechClient(credentials=credentials)\n",
        "\n",
        "\n",
        "def narrator_tts(text, output_file=\"speech.mp3\"):\n",
        "    \"\"\"Convert text to speech using Google WaveNet for the narrator.\"\"\"\n",
        "\n",
        "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "    voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code=\"en-IN\",\n",
        "        name=\"en-IN-Chirp3-HD-Zephyr\",  # Choose a narrator voice\n",
        "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
        "    )\n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
        "    )\n",
        "\n",
        "    response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "    with open(output_file, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "    print(f\"âœ… Narration saved as {output_file}\")\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def charactor_tts(text, output_file=\"speech.mp3\", emotion=\"neutral\"):\n",
        "    \"\"\"Convert text to speech using Google WaveNet for characters in the story.\"\"\"\n",
        "\n",
        "    # SSML adjustments for stronger emotion variation\n",
        "    emotion_settings = {\n",
        "        \"joy\": {\"rate\": \"medium\", \"pitch\": \"+15%\", \"volume_gain_db\": 2, \"speaking_rate\": 1.2},\n",
        "        \"sadness\": {\"rate\": \"slow\", \"pitch\": \"-10%\", \"volume_gain_db\": -2, \"speaking_rate\": 1},\n",
        "        \"anger\": {\"rate\": \"medium\", \"pitch\": \"+20%\", \"volume_gain_db\": 4}, \"speaking_rate\": 1.2,\n",
        "        \"fear\": {\"rate\": \"medium\", \"pitch\": \"-15%\", \"volume_gain_db\": 0, \"speaking_rate\": 0.9},\n",
        "        \"neutral\": {\"rate\": \"normal\", \"pitch\": \"0%\", \"volume_gain_db\": 0, \"speaking_rate\": 1}\n",
        "    }\n",
        "\n",
        "    settings = emotion_settings.get(emotion, emotion_settings[\"neutral\"])\n",
        "\n",
        "    ssml_text = f\"\"\"\n",
        "    <speak>\n",
        "        <prosody rate=\"{settings['rate']}\" pitch=\"{settings['pitch']}\">\n",
        "            {text}\n",
        "        </prosody>\n",
        "    </speak>\n",
        "    \"\"\"\n",
        "\n",
        "    synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)\n",
        "    voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code=\"en-IN\",\n",
        "        name=\"en-IN-Chirp3-HD-Zephyr\",  # Indian English Accent\n",
        "        ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
        "    )\n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
        "        volume_gain_db=settings[\"volume_gain_db\"]\n",
        "    )\n",
        "\n",
        "    response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "    with open(output_file, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "    print(f\"âœ… Speech saved as {output_file} with emotion {emotion}\")\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AFwQ1hn3Uu4_"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def emotion_to_speech(sentence, emotion, prev_emotion=None, bg_music=None, is_narration=False):\n",
        "    \"\"\"Modify speech properties based on detected emotion and correctly mix background music.\"\"\"\n",
        "\n",
        "    # Generate speech using Google WaveNet\n",
        "    if is_narration:\n",
        "        speech_file = narrator_tts(sentence, \"speech.mp3\")\n",
        "    else:\n",
        "        speech_file = charactor_tts(sentence, \"speech.mp3\", emotion)\n",
        "    speech_segment = AudioSegment.from_file(speech_file)\n",
        "\n",
        "    # Background music handling\n",
        "    bg_music_files = {\n",
        "        \"joy\": \"/content/bg_joy.mp3\",\n",
        "        \"sadness\": \"/content/bg_sadness.mp3\",\n",
        "        \"anger\": \"/content/bg_anger.mp3\",\n",
        "        \"fear\": \"/content/bg_fear.mp3\",\n",
        "        \"neutral\": \"/content/bg_neutral.mp3\"\n",
        "    }\n",
        "\n",
        "    # Ensure the same background music continues if emotion is unchanged\n",
        "    if prev_emotion == emotion and bg_music is not None:\n",
        "        print(f\"ðŸŽµ Continuing background music for {emotion}\")\n",
        "    else:\n",
        "        bg_file = bg_music_files.get(emotion, \"/content/bg_neutral.mp3\")\n",
        "        if os.path.exists(bg_file):\n",
        "            bg_music = AudioSegment.from_file(bg_file).set_frame_rate(speech_segment.frame_rate)\n",
        "            bg_music = bg_music - 15  # Lower background music volume\n",
        "        else:\n",
        "            bg_music = AudioSegment.silent(duration=len(speech_segment))\n",
        "\n",
        "    # Extend background music if needed\n",
        "    if len(bg_music) < len(speech_segment):\n",
        "        bg_music = bg_music * (len(speech_segment) // len(bg_music) + 1)\n",
        "    bg_music = bg_music[:len(speech_segment)]  # Trim to speech length\n",
        "\n",
        "    # Overlay speech on background music\n",
        "    final_audio = bg_music.overlay(speech_segment)\n",
        "\n",
        "    return final_audio, emotion, bg_music  # Return background music for reuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KEC1QS2vUVqG"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips\n",
        "from pathlib import Path\n",
        "import openai\n",
        "import os\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2t-ro05sUmhB"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "openai.api_key = \"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\"  # ðŸ” Replace with your actual key\n",
        "\n",
        "\n",
        "\n",
        "def generate_image_dalle(prompt_text, image_save_path):\n",
        "    response = openai.images.generate(\n",
        "        model=\"dall-e-3\",\n",
        "        prompt=prompt_text,\n",
        "        size=\"1024x1024\",\n",
        "        quality=\"standard\",\n",
        "        n=1,\n",
        "    )\n",
        "\n",
        "    image_url = response.data[0].url\n",
        "    image_data = requests.get(image_url).content\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "    image.save(image_save_path)\n",
        "    return image_save_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HsbhctVMUwR4"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def emotion_to_speech(sentence, emotion, prev_emotion=None, bg_music=None, is_narration=False, save_path=\"speech.mp3\"):\n",
        "    if is_narration:\n",
        "        speech_file = narrator_tts(sentence, save_path)\n",
        "    else:\n",
        "        speech_file = charactor_tts(sentence, save_path, emotion)\n",
        "    speech_segment = AudioSegment.from_file(speech_file)\n",
        "\n",
        "    bg_music_files = {\n",
        "        \"joy\": \"/content/bg_joy.mp3\",\n",
        "        \"sadness\": \"/content/bg_sadness.mp3\",\n",
        "        \"anger\": \"/content/bg_anger.mp3\",\n",
        "        \"fear\": \"/content/bg_fear.mp3\",\n",
        "        \"neutral\": \"/content/bg_neutral.mp3\"\n",
        "    }\n",
        "\n",
        "    if prev_emotion == emotion and bg_music is not None:\n",
        "        print(f\"ðŸŽµ Continuing background music for {emotion}\")\n",
        "    else:\n",
        "        bg_file = bg_music_files.get(emotion, \"/content/bg_neutral.mp3\")\n",
        "        if os.path.exists(bg_file):\n",
        "            bg_music = AudioSegment.from_file(bg_file).set_frame_rate(speech_segment.frame_rate) - 15\n",
        "        else:\n",
        "            bg_music = AudioSegment.silent(duration=len(speech_segment))\n",
        "\n",
        "    if len(bg_music) < len(speech_segment):\n",
        "        bg_music *= (len(speech_segment) // len(bg_music) + 1)\n",
        "\n",
        "    bg_music = bg_music[:len(speech_segment)]\n",
        "    final_audio = bg_music.overlay(speech_segment)\n",
        "\n",
        "    final_audio.export(save_path, format=\"mp3\")\n",
        "    return save_path, emotion, bg_music\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FNINTDS4Z7jN"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips\n",
        "\n",
        "def merge_audio_with_images(image_paths, audio_paths, output_video=\"final_story.mp4\"):\n",
        "    video_clips = []\n",
        "    for img_path, audio_path in zip(image_paths, audio_paths):\n",
        "        audio = AudioFileClip(audio_path)\n",
        "        img_clip = ImageClip(img_path).set_duration(audio.duration)\n",
        "        img_clip = img_clip.set_audio(audio)\n",
        "        video_clips.append(img_clip)\n",
        "\n",
        "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "    final_video.write_videofile(output_video, fps=24)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t2oFBgBGyzv4",
        "outputId": "bd820dba-ffdc-443a-e237-52da7b9f0120"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from IPython.display import Video\n",
        "import os\n",
        "\n",
        "file_path = \"/content/st4.txt\"  # Change this to your file\n",
        "\n",
        "# STEP 1: Load and preprocess\n",
        "if file_path.endswith(\".txt\"):\n",
        "    input_text = read_text_file(file_path)\n",
        "elif file_path.endswith(\".pdf\"):\n",
        "    input_text = read_pdf_file(file_path)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file format. Use .txt or .pdf\")\n",
        "\n",
        "sentences = preprocess_text(input_text)\n",
        "\n",
        "image_paths = []\n",
        "audio_paths = []\n",
        "subtitle_entries = []\n",
        "\n",
        "prev_emotion = None\n",
        "bg_music = None\n",
        "current_time = 0.0  # Start subtitle timing from 0\n",
        "\n",
        "# STEP 2: Process every 3-sentence group\n",
        "for idx in range(0, len(sentences), 3):\n",
        "    sentence_group = sentences[idx:idx+3]\n",
        "    combined_sentence = \" \".join(sentence_group).strip()\n",
        "\n",
        "    print(f\"ðŸ“– Processing Sentence Group {idx//3}: {combined_sentence}\")\n",
        "\n",
        "    # ðŸŽ¨ Image generation\n",
        "    image_path = f\"/content/image_{idx//3}.png\"\n",
        "    generate_image_dalle(combined_sentence, image_path)\n",
        "    image_paths.append(image_path)\n",
        "\n",
        "    # ðŸ”Š Audio generation\n",
        "    emotion = detect_emotion(combined_sentence)\n",
        "    audio_path = f\"/content/audio_{idx//3}.mp3\"\n",
        "    emotion_to_speech(\n",
        "        combined_sentence, emotion, prev_emotion, bg_music,\n",
        "        is_narration=not (combined_sentence.startswith('\"') and combined_sentence.endswith('\"')),\n",
        "        save_path=audio_path\n",
        "    )\n",
        "    audio_paths.append(audio_path)\n",
        "    prev_emotion = emotion\n",
        "\n",
        "    # STEP 3: Subtitles (per sentence timing)\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    total_duration = audio.duration_seconds\n",
        "\n",
        "    total_chars = sum(len(s) for s in sentence_group)\n",
        "    for sentence in sentence_group:\n",
        "        proportion = len(sentence) / total_chars\n",
        "        sentence_duration = proportion * total_duration\n",
        "        subtitle_entries.append({\n",
        "            \"start\": current_time,\n",
        "            \"end\": current_time + sentence_duration,\n",
        "            \"text\": sentence\n",
        "        })\n",
        "        current_time += sentence_duration\n",
        "\n",
        "# STEP 4: Generate subtitle file (.ass format)\n",
        "ass_path = \"/content/subtitles.ass\"\n",
        "with open(ass_path, \"w\") as f:\n",
        "    f.write(\"\"\"[Script Info]\n",
        "ScriptType: v4.00+\n",
        "PlayResX: 1280\n",
        "PlayResY: 720\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut,\n",
        "        ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
        "Style: Default,Arial,32,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,\n",
        "       100,100,0,0,1,2,0,2,10,10,40,1\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
        "\"\"\")\n",
        "    for entry in subtitle_entries:\n",
        "        def ass_time(t):\n",
        "            h = int(t // 3600)\n",
        "            m = int((t % 3600) // 60)\n",
        "            s = int(t % 60)\n",
        "            cs = int((t - int(t)) * 100)  # centiseconds\n",
        "            return f\"{h:01}:{m:02}:{s:02}.{cs:02}\"\n",
        "\n",
        "        f.write(f\"Dialogue: 0,{ass_time(entry['start'])},{ass_time(entry['end'])},Default,,0,0,0,,{entry['text']}\\n\")\n",
        "\n",
        "# STEP 5: Merge images and audios into video (function you already have)\n",
        "merge_audio_with_images(image_paths, audio_paths, output_video=\"/content/final_emotion_story.mp4\")\n",
        "\n",
        "# STEP 6: Burn subtitles onto video\n",
        "!ffmpeg -y -i \"/content/final_emotion_story.mp4\" -vf \"ass={ass_path}\" \"/content/final_emotion_story_subtitled.mp4\"\n",
        "\n",
        "# STEP 7: Show final video with subtitles\n",
        "Video(\"/content/final_emotion_story_subtitled.mp4\", embed=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NP4JlhqZgmKi",
        "outputId": "512683a3-9fac-4e66-b871-71d8b4c6c94c"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "# ðŸŽ¥ Display the final video in notebook\n",
        "Video(\"/content/final_emotion_story.mp4\", embed=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
